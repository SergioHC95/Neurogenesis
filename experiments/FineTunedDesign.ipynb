{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10add22dcb7648ef8a143596132f0349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     87\u001b[39m patience, patience_counter = \u001b[32m5\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     train_loss, train_acc = run_epoch(train_loader, model, criterion, optimizer)\n\u001b[32m     91\u001b[39m     val_loss, val_acc = run_epoch(val_loader, model, criterion)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     93\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     94\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal Acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(loader, model, criterion, optimizer)\u001b[39m\n\u001b[32m     71\u001b[39m loss = criterion(logits, y)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     loss.backward()\n\u001b[32m     74\u001b[39m     nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m     75\u001b[39m     optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sergi\\anaconda3\\envs\\cortex\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m torch.autograd.backward(\n\u001b[32m    523\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001b[32m    524\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sergi\\anaconda3\\envs\\cortex\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m Variable._execution_engine.run_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    267\u001b[39m     tensors,\n\u001b[32m    268\u001b[39m     grad_tensors_,\n\u001b[32m    269\u001b[39m     retain_graph,\n\u001b[32m    270\u001b[39m     create_graph,\n\u001b[32m    271\u001b[39m     inputs,\n\u001b[32m    272\u001b[39m     allow_unreachable=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    273\u001b[39m     accumulate_grad=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    274\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for best experience in Jupyter\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ----- Model Definition -----\n",
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.out(x)\n",
    "\n",
    "# ----- Data Augmentation & Normalization -----\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load MNIST and split into train/val\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_size = 6000\n",
    "train_size = len(dataset) - val_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "# Use no augmentation for validation\n",
    "val_set.dataset.transform = transform\n",
    "\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "\n",
    "# ----- Model, Optimizer, Loss -----\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = MNIST_MLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ----- Training Loop -----\n",
    "def run_epoch(loader, model, criterion, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, leave=False)\n",
    "    for x, y in loop:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "patience, patience_counter = 5, 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = run_epoch(train_loader, model, criterion, optimizer)\n",
    "    val_loss, val_acc = run_epoch(val_loader, model, criterion)\n",
    "    print(f\"Epoch {epoch:02d}: \"\n",
    "          f\"Train Loss {train_loss:.4f} | \"\n",
    "          f\"Val Loss {val_loss:.4f} | \"\n",
    "          f\"Val Acc {val_acc*100:.2f}%\")\n",
    "    # Early stopping (optional)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# ----- Test Evaluation -----\n",
    "test_loss, test_acc = run_epoch(test_loader, model, criterion)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7361535948db4fe69a317d55c9b81817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90314625b2dc47e987592d39f83ed7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss 0.2371 | Val Loss 0.1168 | Val Acc 96.73%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db0bebab8a344f4ad5e95c1644e7a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d238cba8dff44e2f902d03915f59ccf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02: Train Loss 0.0881 | Val Loss 0.1047 | Val Acc 97.08%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253085deca4e4570a34280727048845f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249917a18a7545c2bae1b0803c2c8721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03: Train Loss 0.0560 | Val Loss 0.0778 | Val Acc 97.75%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca552b2ab09648a69f0e0301540ea8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b251ad23da5941d7b49afa0f0cdac217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04: Train Loss 0.0450 | Val Loss 0.0820 | Val Acc 97.77%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccb9552e3be4347be288e698bdd84cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05648966f839408389fd06e5714c339d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05: Train Loss 0.0333 | Val Loss 0.0859 | Val Acc 97.52%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3003e045b0184842b694f3c89a1df690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2df446d757e491dad2803b84d900b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06: Train Loss 0.0265 | Val Loss 0.0912 | Val Acc 97.60%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b003d60660b047a78a86ee3cc900d42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9354d67829874eda8e2e30b85a0b7e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07: Train Loss 0.0243 | Val Loss 0.0869 | Val Acc 97.55%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f22f0910ad420da5bba93fe7d167c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08725d6eaf444906bc59818425187d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08: Train Loss 0.0193 | Val Loss 0.0915 | Val Acc 97.87%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84aa7521946e420e92660439120292c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.95%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for best experience in Jupyter\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ----- Model Definition -----\n",
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.out = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)\n",
    "\n",
    "# ----- Data Augmentation & Normalization -----\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "\n",
    "# Load MNIST and split into train/val\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_size = 6000\n",
    "train_size = len(dataset) - val_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "# Use no augmentation for validation\n",
    "val_set.dataset.transform = transform\n",
    "\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "\n",
    "# ----- Model, Optimizer, Loss -----\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = MNIST_MLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ----- Training Loop -----\n",
    "def run_epoch(loader, model, criterion, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, leave=False)\n",
    "    for x, y in loop:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "patience, patience_counter = 5, 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = run_epoch(train_loader, model, criterion, optimizer)\n",
    "    val_loss, val_acc = run_epoch(val_loader, model, criterion)\n",
    "    print(f\"Epoch {epoch:02d}: \"\n",
    "          f\"Train Loss {train_loss:.4f} | \"\n",
    "          f\"Val Loss {val_loss:.4f} | \"\n",
    "          f\"Val Acc {val_acc*100:.2f}%\")\n",
    "    # Early stopping (optional)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# ----- Test Evaluation -----\n",
    "test_loss, test_acc = run_epoch(test_loader, model, criterion)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffb5c0861354d9cb6b79138edf76050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423139f3130e41ffa7db1d8b989b8008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss 0.2888 | Val Loss 0.1462 | Val Acc 95.65%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa201f6486040d0a9944a29721f7d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a1f703d6ef40adbf83087417d1ff76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02: Train Loss 0.1052 | Val Loss 0.1414 | Val Acc 95.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a95cabd2b94df9b428eb94e55a4ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2ea75e2e2f42d280d76e72da7d9888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03: Train Loss 0.0680 | Val Loss 0.0936 | Val Acc 97.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd9d7b4433a4f2bb98bb15fdff409f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80fd38590b34eaa8b0f2f0784e4d409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04: Train Loss 0.0492 | Val Loss 0.1153 | Val Acc 96.58%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1308bab3ca246e99d80177a7036fe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05723c226464ac49a28f78b8ec41be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05: Train Loss 0.0391 | Val Loss 0.0818 | Val Acc 97.35%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f714174751405db5b59239c3733f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a5608ef44947f48d3a41f76d8b464b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06: Train Loss 0.0292 | Val Loss 0.0894 | Val Acc 97.52%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25242895452f4657b770013df474141e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5f2128795b4e64852c84f7c8460aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07: Train Loss 0.0243 | Val Loss 0.0892 | Val Acc 97.58%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af57e0662284228afaef9b8d57c0d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbb9b7e32b9488fa0a9763bbb10c5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08: Train Loss 0.0220 | Val Loss 0.0908 | Val Acc 97.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33cc43f3d0f4bcda2328df38d910b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b050b0ea25cb4689ac1d008b2abe8ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09: Train Loss 0.0196 | Val Loss 0.1086 | Val Acc 97.35%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1143e62a3b974d7390099db30fd4c4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0bd51d77954a05b64ffa46865a8dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0146 | Val Loss 0.0892 | Val Acc 97.62%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05d6ebed49543f9b691e7e36960a091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.77%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for best experience in Jupyter\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ----- Model Definition -----\n",
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.out = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)\n",
    "\n",
    "# ----- Data Augmentation & Normalization -----\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "\n",
    "# Load MNIST and split into train/val\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_size = 6000\n",
    "train_size = len(dataset) - val_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "# Use no augmentation for validation\n",
    "val_set.dataset.transform = transform\n",
    "\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "\n",
    "# ----- Model, Optimizer, Loss -----\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = MNIST_MLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ----- Training Loop -----\n",
    "def run_epoch(loader, model, criterion, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, leave=False)\n",
    "    for x, y in loop:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "patience, patience_counter = 5, 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = run_epoch(train_loader, model, criterion, optimizer)\n",
    "    val_loss, val_acc = run_epoch(val_loader, model, criterion)\n",
    "    print(f\"Epoch {epoch:02d}: \"\n",
    "          f\"Train Loss {train_loss:.4f} | \"\n",
    "          f\"Val Loss {val_loss:.4f} | \"\n",
    "          f\"Val Acc {val_acc*100:.2f}%\")\n",
    "    # Early stopping (optional)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# ----- Test Evaluation -----\n",
    "test_loss, test_acc = run_epoch(test_loader, model, criterion)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cortex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
